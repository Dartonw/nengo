{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "do_save = True\n",
      "do_load = True\n",
      "do_graph = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import nengo\n",
      "import nengo.spa as spa\n",
      "from nengo.utils.compat import OrderedDict\n",
      "from nengo.utils.distributions import Uniform, UniformHypersphere\n",
      "from nengo.networks.associative import AutoAssociative, HeteroAssociative"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "\n",
      "class DFA(object):\n",
      "    \n",
      "    def __init__(self, states, transitions):\n",
      "        self.states = states\n",
      "        self.transitions = transitions\n",
      "        \n",
      "    @property\n",
      "    def adjacency_dict(self):\n",
      "        adj_list = defaultdict(list)\n",
      "        for pre, post in self.transitions:\n",
      "            adj_list[pre].append(post)\n",
      "        return adj_list\n",
      "    \n",
      "    @property\n",
      "    def actions(self, state_module='state', state_weight=0.2, rule_weight=0.5, \n",
      "                state_gain=4.0, utility_offset=-0.2):\n",
      "        action_matches = {}\n",
      "        action_effects = {}\n",
      "                \n",
      "        for (pre, post), utility in self.transitions.iteritems():\n",
      "            if utility is None:\n",
      "                utility = '1.0'\n",
      "            transition_name = '%s_TO_%s' % (pre, post)\n",
      "            action_matches[transition_name] = '%s*dot(%s, F_%s) + %s*(%s) + %s' % (\n",
      "                state_weight, state_module, pre, rule_weight, \n",
      "                utility, utility_offset)\n",
      "            action_effects[transition_name] = '%s=%s*%s' % (\n",
      "                state_module, state_gain, post)\n",
      "        \n",
      "        for post, effect in self.states.iteritems():\n",
      "            latch_matches = []\n",
      "            latch_effects = []\n",
      "            all_effects = effect.split(',')\n",
      "            for subeffect in all_effects:\n",
      "                # Every module in the state's effect must have _latched\n",
      "                lvalue, rvalue = subeffect.split('=', 1)\n",
      "                latch = lvalue.strip()\n",
      "                latch_matches.append('%s*dot(%s_latched, 1)' % (\n",
      "                    rule_weight / len(all_effects), latch))\n",
      "                latch_effects.append('%s_latch=1' % latch)\n",
      "                \n",
      "            action_matches[post] = '%s*dot(%s, %s) - (%s) + %s' % (\n",
      "                state_weight, state_module, post, ' + '.join(latch_matches),\n",
      "                rule_weight + utility_offset)\n",
      "            action_effects[post] = '%s, %s, %s=%s' % (\n",
      "                effect, ', '.join(latch_effects), state_module, post)\n",
      "            \n",
      "            action_matches['F_%s' % post] = '%s*dot(%s, %s) + %s + %s' % (\n",
      "                state_weight, state_module, post, ' + '.join(latch_matches),\n",
      "                utility_offset)\n",
      "            action_effects['F_%s' % post] = '%s=%s*F_%s' % (\n",
      "                state_module, state_gain, post)\n",
      "    \n",
      "        actions = {}\n",
      "        for name in action_matches:\n",
      "            actions[name] = '%s  -->  %s' % (\n",
      "                action_matches[name], action_effects[name])\n",
      "        \n",
      "        return actions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class BFS(spa.SPA):\n",
      "    \n",
      "    control_dfa = DFA(\n",
      "        states = {\n",
      "            'INIT': 'graph_key=v_0, queue_head=v_0, queue_tail=v_0, queue_learning=-1',\n",
      "            'IF': 'queue_key=graph_edge',\n",
      "            'IN_Q': 'temp=graph_next',\n",
      "            'LOOK_G': 'graph_key=temp',\n",
      "            'NOTIN_Q': 'queue_key=queue_tail, queue_value=graph_edge, queue_learning=1',\n",
      "            'ADDED_Q': 'queue_tail=graph_edge, queue_learning=-1, temp=graph_next',\n",
      "            'END_G': 'queue_key=queue_head',\n",
      "            'NEXT_Q': 'queue_head=queue_output, queue_key=queue_output',\n",
      "        }, \n",
      "        transitions = {\n",
      "            ('INIT', 'IF') : None,\n",
      "            ('IF', 'NOTIN_Q') : '1 - dot(queue_has_key, 1)',\n",
      "            ('IF', 'IN_Q') : 'dot(queue_has_key, 1)',\n",
      "            ('IN_Q', 'LOOK_G') : None,\n",
      "            ('NOTIN_Q', 'NOTIN_Q') : '0.8',\n",
      "            ('NOTIN_Q', 'ADDED_Q') : 'dot(queue_value, queue_output)',\n",
      "            ('ADDED_Q', 'LOOK_G') : None,\n",
      "            ('LOOK_G', 'IF') : '1 - dot(graph_key, NULL)',\n",
      "            ('LOOK_G', 'END_G') : 'dot(graph_key, NULL)',\n",
      "            ('END_G', 'NEXT_Q') : None,\n",
      "            ('NEXT_Q', 'IF') : None,\n",
      "        })\n",
      "\n",
      "    def __init__(self, adjacency_dict, initial_vertex, dimensions_graph, dimensions_state, neurons_per_item=50):\n",
      "        super(BFS, self).__init__()\n",
      "        \n",
      "        # Put the graph into a static Dict\n",
      "        initial_keys = []\n",
      "        initial_values = []\n",
      "        v_0 = 'V_%s' % initial_vertex\n",
      "        num_vertices = len(adjacency_dict)\n",
      "        graph_vocab = self.get_default_vocab(dimensions_graph)\n",
      "        for i, adj in adjacency_dict.items():\n",
      "            for num, j in enumerate(adj):\n",
      "                key = 'V_%s' % i if num == 0 else 'P_%s_%d' % (i, num)\n",
      "                next_key = 'P_%s_%d' % (i, num + 1) if num != len(adj) - 1 else 'NULL' \n",
      "                initial_keys.append(graph_vocab.parse(key).v)\n",
      "                initial_values.append(graph_vocab.parse('V_%s*EDGE+%s*NEXT' % (j, next_key)).v)\n",
      "        \n",
      "        self.graph = AutoAssociative(\n",
      "            nengo.LIF(neurons_per_item*len(initial_keys)), len(initial_keys),\n",
      "            initial_keys=initial_keys, initial_values=initial_values)\n",
      "        \n",
      "        # Interface with the graph using SPA blocks\n",
      "        self.graph_key = spa.DoubleLatch(dimensions=dimensions_graph)\n",
      "        self.graph_output = spa.Buffer(dimensions=dimensions_graph)\n",
      "        nengo.Connection(self.graph_key.state.output, self.graph.key)\n",
      "        nengo.Connection(self.graph.output, self.graph_output.state.input, filter=None)\n",
      "        self.graph_edge = spa.Cleanup(graph_vocab)\n",
      "        self.graph_next = spa.Cleanup(graph_vocab)\n",
      "\n",
      "        # Create a queue using a Dict and interface with SPA blocks\n",
      "        self.queue = AutoAssociative(\n",
      "            nengo.LIF(10*neurons_per_item*num_vertices), 10*num_vertices, dimensions_graph, dimensions_graph,\n",
      "            initial_keys=[graph_vocab.parse(v_0).v], initial_values=[graph_vocab.parse('NULL').v])\n",
      "        self.queue_key = spa.DoubleLatch(dimensions=dimensions_graph)\n",
      "        self.queue_value = spa.DoubleLatch(dimensions=dimensions_graph)\n",
      "        self.queue_learning = spa.DoubleLatch(dimensions=1)\n",
      "        self.queue_output = spa.Buffer(dimensions=dimensions_graph)\n",
      "        self.queue_has_key = spa.Buffer(dimensions=1, subdimensions=1)\n",
      "        nengo.Connection(self.queue_key.state.output, self.queue.key)\n",
      "        nengo.Connection(self.queue_value.state.output, self.queue.value)\n",
      "        nengo.Connection(self.queue_learning.state.output, self.queue.learning)\n",
      "        nengo.Connection(self.queue.output, self.queue_output.state.input, filter=None)\n",
      "        nengo.Connection(self.queue.has_key, self.queue_has_key.state.input, filter=None)\n",
      "\n",
      "        # Variables\n",
      "        self.state = spa.Memory(dimensions=dimensions_state)\n",
      "        self.temp = spa.DoubleLatch(dimensions=dimensions_graph)\n",
      "        self.queue_head = spa.DoubleLatch(dimensions=dimensions_graph)\n",
      "        self.queue_tail = spa.DoubleLatch(dimensions=dimensions_graph)\n",
      "        \n",
      "        # Input\n",
      "        self.v_0 = spa.Buffer(dimensions=dimensions_graph)\n",
      "        \n",
      "        # Control flow\n",
      "        actions = self.control_dfa.actions\n",
      "        for name, action in actions.items():\n",
      "            print \"[%s] %s\" % (name, action)\n",
      "        actions = spa.Actions(**actions)\n",
      "        cortical_actions = spa.Actions('graph_edge=graph_output*~EDGE',\n",
      "                                       'graph_next=graph_output*~NEXT')\n",
      "        self.bg = spa.BasalGanglia(actions=actions, radius=3, n_neurons_per_ensemble=200)\n",
      "        self.thal = spa.Thalamus(self.bg)\n",
      "        self.cortical = spa.Cortical(cortical_actions)\n",
      "        \n",
      "        # Initialize starting vertex and state\n",
      "        self.input_vertex = spa.Input(v_0=lambda t: v_0)\n",
      "        self.input_state = spa.Input(state=lambda t: '4*INIT' if t < 0.02 else '0')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print BFS.control_dfa.adjacency_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "defaultdict(<type 'list'>, {'ADDED_Q': ['LOOK_G'], 'NEXT_Q': ['IF'], 'NOTIN_Q': ['NOTIN_Q', 'ADDED_Q'], 'INIT': ['IF'], 'LOOK_G': ['IF', 'END_G'], 'IF': ['NOTIN_Q', 'IN_Q'], 'END_G': ['NEXT_Q'], 'IN_Q': ['LOOK_G']})\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "adjacency_dict = {\n",
      "    '0': ['1', '2'],\n",
      "    '1': ['0', '3'],\n",
      "    '2': ['0'],\n",
      "    '3': ['0', '1', '2'],\n",
      "}\n",
      "\n",
      "model = nengo.Network()\n",
      "with model:\n",
      "    bfs = BFS(adjacency_dict, '0', 32, 64)\n",
      "\n",
      "    modules = ('v_0', 'state', 'graph_key', 'graph_key_latched', \n",
      "               'graph_edge', 'graph_next',\n",
      "               'queue_head', 'queue_head_latched', 'queue_tail', 'queue_tail_latched', \n",
      "               'queue_key', 'queue_key_latched', 'queue_value', 'queue_value_latched', \n",
      "               'queue_learning', 'queue_learning_latched',\n",
      "               'queue_output', 'queue_has_key', \n",
      "               'temp', 'temp_latched')\n",
      "    module_probes = OrderedDict([\n",
      "        (module, nengo.Probe(bfs.get_module_output(module)[0], filter=0.01))\n",
      "        for module in modules])\n",
      "    actions_probe = nengo.Probe(bfs.thal.actions.output, filter=0.03)\n",
      "    utilities_probe = nengo.Probe(bfs.bg.input, filter=0.03)\n",
      "    bg_output_probe = nengo.Probe(bfs.bg.output, filter=0.03)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[NEXT_Q] 0.2*dot(state, NEXT_Q) - (0.25*dot(queue_head_latched, 1) + 0.25*dot(queue_key_latched, 1)) + 0.3  -->  queue_head=queue_output, queue_key=queue_output, queue_head_latch=1, queue_key_latch=1, state=NEXT_Q\n",
        "[ADDED_Q_TO_LOOK_G] 0.2*dot(state, F_ADDED_Q) + 0.5*(1.0) + -0.2  -->  state=4.0*LOOK_G\n",
        "[ADDED_Q] 0.2*dot(state, ADDED_Q) - (0.166666666667*dot(queue_tail_latched, 1) + 0.166666666667*dot(queue_learning_latched, 1) + 0.166666666667*dot(temp_latched, 1)) + 0.3  -->  queue_tail=graph_edge, queue_learning=-1, temp=graph_next, queue_tail_latch=1, queue_learning_latch=1, temp_latch=1, state=ADDED_Q\n",
        "[F_LOOK_G] 0.2*dot(state, LOOK_G) + 0.5*dot(graph_key_latched, 1) + -0.2  -->  state=4.0*F_LOOK_G\n",
        "[END_G] 0.2*dot(state, END_G) - (0.5*dot(queue_key_latched, 1)) + 0.3  -->  queue_key=queue_head, queue_key_latch=1, state=END_G\n",
        "[F_INIT] 0.2*dot(state, INIT) + 0.125*dot(graph_key_latched, 1) + 0.125*dot(queue_head_latched, 1) + 0.125*dot(queue_tail_latched, 1) + 0.125*dot(queue_learning_latched, 1) + -0.2  -->  state=4.0*F_INIT\n",
        "[LOOK_G_TO_END_G] 0.2*dot(state, F_LOOK_G) + 0.5*(dot(graph_key, NULL)) + -0.2  -->  state=4.0*END_G\n",
        "[F_IN_Q] 0.2*dot(state, IN_Q) + 0.5*dot(temp_latched, 1) + -0.2  -->  state=4.0*F_IN_Q\n",
        "[INIT] 0.2*dot(state, INIT) - (0.125*dot(graph_key_latched, 1) + 0.125*dot(queue_head_latched, 1) + 0.125*dot(queue_tail_latched, 1) + 0.125*dot(queue_learning_latched, 1)) + 0.3  -->  graph_key=v_0, queue_head=v_0, queue_tail=v_0, queue_learning=-1, graph_key_latch=1, queue_head_latch=1, queue_tail_latch=1, queue_learning_latch=1, state=INIT\n",
        "[IF_TO_IN_Q] 0.2*dot(state, F_IF) + 0.5*(dot(queue_has_key, 1)) + -0.2  -->  state=4.0*IN_Q\n",
        "[F_END_G] 0.2*dot(state, END_G) + 0.5*dot(queue_key_latched, 1) + -0.2  -->  state=4.0*F_END_G\n",
        "[F_NEXT_Q] 0.2*dot(state, NEXT_Q) + 0.25*dot(queue_head_latched, 1) + 0.25*dot(queue_key_latched, 1) + -0.2  -->  state=4.0*F_NEXT_Q\n",
        "[F_IF] 0.2*dot(state, IF) + 0.5*dot(queue_key_latched, 1) + -0.2  -->  state=4.0*F_IF\n",
        "[IN_Q] 0.2*dot(state, IN_Q) - (0.5*dot(temp_latched, 1)) + 0.3  -->  temp=graph_next, temp_latch=1, state=IN_Q\n",
        "[IF] 0.2*dot(state, IF) - (0.5*dot(queue_key_latched, 1)) + 0.3  -->  queue_key=graph_edge, queue_key_latch=1, state=IF\n",
        "[F_NOTIN_Q] 0.2*dot(state, NOTIN_Q) + 0.166666666667*dot(queue_key_latched, 1) + 0.166666666667*dot(queue_value_latched, 1) + 0.166666666667*dot(queue_learning_latched, 1) + -0.2  -->  state=4.0*F_NOTIN_Q\n",
        "[NEXT_Q_TO_IF] 0.2*dot(state, F_NEXT_Q) + 0.5*(1.0) + -0.2  -->  state=4.0*IF\n",
        "[IF_TO_NOTIN_Q] 0.2*dot(state, F_IF) + 0.5*(1 - dot(queue_has_key, 1)) + -0.2  -->  state=4.0*NOTIN_Q\n",
        "[INIT_TO_IF] 0.2*dot(state, F_INIT) + 0.5*(1.0) + -0.2  -->  state=4.0*IF\n",
        "[NOTIN_Q] 0.2*dot(state, NOTIN_Q) - (0.166666666667*dot(queue_key_latched, 1) + 0.166666666667*dot(queue_value_latched, 1) + 0.166666666667*dot(queue_learning_latched, 1)) + 0.3  -->  queue_key=queue_tail, queue_value=graph_edge, queue_learning=1, queue_key_latch=1, queue_value_latch=1, queue_learning_latch=1, state=NOTIN_Q\n",
        "[F_ADDED_Q] 0.2*dot(state, ADDED_Q) + 0.166666666667*dot(queue_tail_latched, 1) + 0.166666666667*dot(queue_learning_latched, 1) + 0.166666666667*dot(temp_latched, 1) + -0.2  -->  state=4.0*F_ADDED_Q\n",
        "[IN_Q_TO_LOOK_G] 0.2*dot(state, F_IN_Q) + 0.5*(1.0) + -0.2  -->  state=4.0*LOOK_G\n",
        "[LOOK_G] 0.2*dot(state, LOOK_G) - (0.5*dot(graph_key_latched, 1)) + 0.3  -->  graph_key=temp, graph_key_latch=1, state=LOOK_G\n",
        "[NOTIN_Q_TO_ADDED_Q] 0.2*dot(state, F_NOTIN_Q) + 0.5*(dot(queue_value, queue_output)) + -0.2  -->  state=4.0*ADDED_Q\n",
        "[LOOK_G_TO_IF] 0.2*dot(state, F_LOOK_G) + 0.5*(1 - dot(graph_key, NULL)) + -0.2  -->  state=4.0*IF\n",
        "[END_G_TO_NEXT_Q] 0.2*dot(state, F_END_G) + 0.5*(1.0) + -0.2  -->  state=4.0*NEXT_Q\n",
        "[NOTIN_Q_TO_NOTIN_Q] 0.2*dot(state, F_NOTIN_Q) + 0.5*(0.8) + -0.2  -->  state=4.0*NOTIN_Q\n"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sim = nengo.Simulator(model)\n",
      "sim.run(5.)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if do_save:\n",
      "    all_probes = module_probes.items() + [('actions_probe', actions_probe), ('utilities_probe', utilities_probe), ('bg_output_probe', bg_output_probe)]\n",
      "    all_data = dict((name, sim.data[probe]) for name, probe in all_probes) \n",
      "    np.savez('bfs', **all_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if do_load:\n",
      "    loaded_data = np.load('bfs.npz')\n",
      "    module_data = OrderedDict((name, loaded_data[name]) for name in module_probes)\n",
      "    actions_data = loaded_data['actions_probe']\n",
      "    utilities_data = loaded_data['utilities_probe']\n",
      "    bg_output_data = loaded_data['bg_output_probe']\n",
      "else:\n",
      "    module_data = OrderedDict((name, sim.data[probe]) for name, probe in module_probes.items())\n",
      "    actions_data = sim.data[actions_probe]\n",
      "    utilities_data = sim.data[utilities_probe]\n",
      "    bg_output_data = sim.data[bg_output_probe]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def do_plot(data):\n",
      "    for i, y in enumerate(data.T):\n",
      "        plt.plot(sim.trange(), y, marker=['o', 's', 'v'][i%3])\n",
      "\n",
      "if do_graph:  \n",
      "    plt.figure(figsize=(10, 10))\n",
      "    plt.title(\"Utilities\")\n",
      "    do_plot(utilities_data)\n",
      "    plt.legend([action.name for action in bfs.bg.actions.actions])\n",
      "    \n",
      "    plt.figure(figsize=(10, 10))\n",
      "    plt.title(\"BG Output\")\n",
      "    do_plot(bg_output_data)\n",
      "    plt.legend([action.name for action in bfs.bg.actions.actions])\n",
      "    \n",
      "    plt.figure(figsize=(10, 10))\n",
      "    plt.title(\"Rules\")\n",
      "    do_plot(actions_data)\n",
      "    plt.legend([action.name for action in bfs.bg.actions.actions])\n",
      "    \n",
      "    for module, data in module_data.items():\n",
      "        plt.figure(figsize=(10, 10))\n",
      "        plt.title(module)\n",
      "        if data.shape[1] == 1:\n",
      "            plt.plot(sim.trange(), data)\n",
      "        else:\n",
      "            do_plot(np.dot(data, bfs.get_module_output(module)[1].vectors.T))\n",
      "            plt.legend(bfs.get_module_output(module)[1].keys, fontsize='small')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    }
   ],
   "metadata": {}
  }
 ]
}