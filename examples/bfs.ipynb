{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import nengo\n",
      "import nengo.spa as spa\n",
      "from nengo.utils.compat import OrderedDict\n",
      "from nengo.utils.distributions import Uniform, UniformHypersphere\n",
      "from nengo.networks.associative import AutoAssociative, HeteroAssociative"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "\n",
      "states = {\n",
      "    'INIT': 'graph_key=v_0, queue_head=v_0, queue_tail=v_0, queue_learning=-1',\n",
      "    'IF': 'queue_key=graph_edge',\n",
      "    'IN_Q': 'temp=graph_next',\n",
      "    'LOOK_G': 'graph_key=temp',\n",
      "    'NOTIN_Q': 'queue_key=queue_tail, queue_value=graph_edge, queue_learning=1',\n",
      "    'ADDED_Q': 'queue_tail=graph_edge, queue_learning=-1, temp=graph_next',\n",
      "    'END_G': 'queue_key=queue_head',\n",
      "    'NEXT_Q': 'queue_head=queue_output, queue_key=queue_output',\n",
      "}\n",
      "\n",
      "transitions = {\n",
      "    ('INIT', 'IF') : None,\n",
      "    ('IF', 'END_G') : 'dot(queue_key, NULL)',\n",
      "    ('IF', 'IN_Q') : 'dot(queue_has_key, 1)',\n",
      "    ('IF', 'NOTIN_Q') : '1 - dot(queue_has_key, 1) - dot(queue_key, NULL)',\n",
      "    ('IN_Q', 'LOOK_G') : None,\n",
      "    ('NOTIN_Q', 'NOTIN_Q') : '0.8',\n",
      "    ('NOTIN_Q', 'ADDED_Q') : 'dot(queue_has_key, 1)',\n",
      "    ('ADDED_Q', 'LOOK_G') : None,\n",
      "    ('LOOK_G', 'IF') : None,\n",
      "    ('END_G', 'NEXT_Q') : None,\n",
      "    ('END_G', 'IF') : None,\n",
      "}\n",
      "\n",
      "def dfa_to_actions(states, transitions, state='state', weight=0.5, gain=1.5):\n",
      "    action_matches = {}\n",
      "    action_effects = {}\n",
      "    \n",
      "    if not (0 < weight < 1):\n",
      "        raise ValueError(\"weight (%s) must be in range (0, 1)\" % weight)\n",
      "    r_weight = 1 - weight\n",
      "    \n",
      "    for (pre, post), utility in transitions.iteritems():\n",
      "        if utility is None:\n",
      "            utility = '1.0'\n",
      "        transition_name = '%s_TO_%s' % (pre, post)\n",
      "        action_matches[transition_name] = '%s*dot(%s, F_%s) + %s*(%s)' % (\n",
      "            weight, state, pre, r_weight, utility)\n",
      "        action_effects[transition_name] = '%s=%s*%s' % (state, gain, post)\n",
      "    \n",
      "    for post, effect in states.iteritems():\n",
      "        \n",
      "        latch_matches = []\n",
      "        latch_effects = []\n",
      "        all_effects = effect.split(',')\n",
      "        for subeffect in all_effects:\n",
      "            lvalue, rvalue = subeffect.split('=', 1)\n",
      "            latch = lvalue.strip()\n",
      "            latch_matches.append('%s*dot(%s_latched, 1)' % (r_weight / len(all_effects), latch))\n",
      "            latch_effects.append('%s_latch=1' % latch)\n",
      "            \n",
      "        action_matches[post] = 'dot(%s, %s) - (%s)' % (state, post, ' + '.join(latch_matches))\n",
      "        action_effects[post] = '%s, %s, %s=%s' % (effect, ', '.join(latch_effects), state, post)\n",
      "        \n",
      "        action_matches['F_%s' % post] = '%s*dot(%s, %s) + %s' % (\n",
      "            weight, state, post, ' + '.join(latch_matches))\n",
      "        action_effects['F_%s' % post] = '%s=%s*F_%s' % (state, gain, post)\n",
      "\n",
      "    actions = {}\n",
      "    for name in action_matches:\n",
      "        actions[name] = '%s  -->  %s' % (action_matches[name], action_effects[name])\n",
      "    \n",
      "    return actions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class BFS(spa.SPA):\n",
      "\n",
      "    def __init__(self, graph, dimensions, neurons_per_item=500, dimensions_state=64, state_weight=0.5):\n",
      "        super(BFS, self).__init__()\n",
      "        \n",
      "        num_vertices = len(graph)\n",
      "        \n",
      "        # Put the graph into a static Dict\n",
      "        initial_keys = []\n",
      "        initial_values = []\n",
      "        graph_vocab = self.get_default_vocab(dimensions)\n",
      "        for i, adj_list in enumerate(graph):\n",
      "            for num, j in enumerate(adj_list):\n",
      "                if not (0 <= j < num_vertices):\n",
      "                    raise ValueError(\"Edge %d->%d out of range\" % (i, j))\n",
      "                key = 'V_%d' % i if num == 0 else 'P_%d_%d' % (i, num)\n",
      "                next_key = 'P_%d_%d' % (i, num + 1) if num != len(adj_list) - 1 else 'NULL' \n",
      "                initial_keys.append(graph_vocab.parse(key).v)\n",
      "                initial_values.append(graph_vocab.parse('EDGE*V_%d+NEXT*%s' % (j, next_key)).v)\n",
      "            #if not len(adj_list):\n",
      "            #    initial_keys.append(graph_vocab.parse('V_%d' % i).v)\n",
      "            #    initial_values.append('NULL')\n",
      "        \n",
      "        self.graph = AutoAssociative(\n",
      "            nengo.LIF(neurons_per_item*len(initial_keys)), len(initial_keys),\n",
      "            initial_keys=initial_keys, initial_values=initial_values)\n",
      "        \n",
      "        # Interface with the graph using SPA blocks\n",
      "        self.graph_key = spa.DoubleLatch(dimensions=dimensions)\n",
      "        self.graph_output = spa.Buffer(dimensions=dimensions)\n",
      "        nengo.Connection(self.graph_key.state.output, self.graph.key)\n",
      "        nengo.Connection(self.graph.output, self.graph_output.state.input, filter=None)\n",
      "        self.graph_edge = spa.Buffer(dimensions=dimensions)\n",
      "        self.graph_next = spa.Buffer(dimensions=dimensions)\n",
      "        \n",
      "        # Create a queue using a Dict and interface with SPA blocks\n",
      "        self.queue = AutoAssociative(\n",
      "            nengo.LIF(neurons_per_item*num_vertices), num_vertices, dimensions, dimensions,\n",
      "            initial_keys=[graph_vocab.parse('V_0').v], initial_values=[graph_vocab.parse('V_0').v])\n",
      "        self.queue_key = spa.DoubleLatch(dimensions=dimensions)\n",
      "        self.queue_value = spa.DoubleLatch(dimensions=dimensions)\n",
      "        self.queue_learning = spa.DoubleLatch(dimensions=1, subdimensions=1)\n",
      "        self.queue_output = spa.Buffer(dimensions=dimensions)\n",
      "        self.queue_has_key = spa.Buffer(dimensions=1, subdimensions=1)\n",
      "        nengo.Connection(self.queue_key.state.output, self.queue.key)\n",
      "        nengo.Connection(self.queue_value.state.output, self.queue.value)\n",
      "        nengo.Connection(self.queue_learning.state.output, self.queue.learning)\n",
      "        nengo.Connection(self.queue.output, self.queue_output.state.input, filter=None)\n",
      "        nengo.Connection(self.queue.has_key, self.queue_has_key.state.input, filter=None)\n",
      "\n",
      "        # Variables\n",
      "        self.state = spa.Buffer(dimensions=dimensions_state)\n",
      "        self.temp = spa.DoubleLatch(dimensions=dimensions)\n",
      "        self.queue_head = spa.DoubleLatch(dimensions=dimensions)\n",
      "        self.queue_tail = spa.DoubleLatch(dimensions=dimensions)\n",
      "        \n",
      "        # Input\n",
      "        self.v_0 = spa.Buffer(dimensions=dimensions)\n",
      "        \n",
      "        # Control flow\n",
      "        actions = dfa_to_actions(states, transitions, weight=state_weight)\n",
      "        for name, action in actions.items():\n",
      "            print \"[%s] %s\" % (name, action)\n",
      "        actions = spa.Actions(**actions)\n",
      "        cortical_actions = spa.Actions('graph_edge=graph_output*~EDGE',\n",
      "                                       'graph_next=graph_output*~NEXT')\n",
      "        self.bg = spa.BasalGanglia(actions=actions)\n",
      "        self.thal = spa.Thalamus(self.bg, rule_threshold=0.55)\n",
      "        self.cortical = spa.Cortical(cortical_actions)\n",
      "        \n",
      "        # Initialize starting vertex and state\n",
      "        self.input_vertex = spa.Input(v_0=lambda t: 'V_0')\n",
      "        self.input_state = spa.Input(state=lambda t: 'INIT' if t < 0.05 else '0')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graph = [[1, 2],\n",
      "         [0, 3],\n",
      "         [0],\n",
      "         [0, 1, 2]]\n",
      "\n",
      "d = 128\n",
      "\n",
      "model = nengo.Network()\n",
      "with model:\n",
      "    bfs = BFS(graph, d)\n",
      "\n",
      "    modules = ('v_0', 'state', 'graph_key', 'graph_key_latched', \n",
      "               'graph_edge', 'graph_next',\n",
      "               'queue_head', 'queue_head_latched', 'queue_tail', 'queue_tail_latched', \n",
      "               'queue_key', 'queue_key_latched', 'queue_value', 'queue_value_latched', \n",
      "               'queue_learning', 'queue_learning_latched',\n",
      "               'queue_output', 'queue_has_key', \n",
      "               'temp', 'temp_latched')\n",
      "    module_probes = OrderedDict([\n",
      "        (module, nengo.Probe(bfs.get_module_output(module)[0], filter=0.01))\n",
      "        for module in modules])\n",
      "    actions_probe = nengo.Probe(bfs.thal.actions.output, filter=0.03)\n",
      "    utilities_probe = nengo.Probe(bfs.bg.input, filter=0.03)\n",
      "    bg_output_probe = nengo.Probe(bfs.bg.output, filter=0.03)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[NEXT_Q] dot(state, NEXT_Q) - (0.25*dot(queue_head_latched, 1) + 0.25*dot(queue_key_latched, 1))  -->  queue_head=queue_output, queue_key=queue_output, queue_head_latch=1, queue_key_latch=1, state=NEXT_Q\n",
        "[ADDED_Q_TO_LOOK_G] 0.5*dot(state, F_ADDED_Q) + 0.5*(1.0)  -->  state=1.5*LOOK_G\n",
        "[NOTIN_Q] dot(state, NOTIN_Q) - (0.166666666667*dot(queue_key_latched, 1) + 0.166666666667*dot(queue_value_latched, 1) + 0.166666666667*dot(queue_learning_latched, 1))  -->  queue_key=queue_tail, queue_value=graph_edge, queue_learning=1, queue_key_latch=1, queue_value_latch=1, queue_learning_latch=1, state=NOTIN_Q\n",
        "[F_LOOK_G] 0.5*dot(state, LOOK_G) + 0.5*dot(graph_key_latched, 1)  -->  state=1.5*F_LOOK_G\n",
        "[END_G] dot(state, END_G) - (0.5*dot(queue_key_latched, 1))  -->  queue_key=queue_head, queue_key_latch=1, state=END_G\n",
        "[F_INIT] 0.5*dot(state, INIT) + 0.125*dot(graph_key_latched, 1) + 0.125*dot(queue_head_latched, 1) + 0.125*dot(queue_tail_latched, 1) + 0.125*dot(queue_learning_latched, 1)  -->  state=1.5*F_INIT\n",
        "[F_IN_Q] 0.5*dot(state, IN_Q) + 0.5*dot(temp_latched, 1)  -->  state=1.5*F_IN_Q\n",
        "[INIT] dot(state, INIT) - (0.125*dot(graph_key_latched, 1) + 0.125*dot(queue_head_latched, 1) + 0.125*dot(queue_tail_latched, 1) + 0.125*dot(queue_learning_latched, 1))  -->  graph_key=v_0, queue_head=v_0, queue_tail=v_0, queue_learning=-1, graph_key_latch=1, queue_head_latch=1, queue_tail_latch=1, queue_learning_latch=1, state=INIT\n",
        "[END_G_TO_IF] 0.5*dot(state, F_END_G) + 0.5*(1.0)  -->  state=1.5*IF\n",
        "[IF_TO_IN_Q] 0.5*dot(state, F_IF) + 0.5*(dot(queue_has_key, 1))  -->  state=1.5*IN_Q\n",
        "[F_END_G] 0.5*dot(state, END_G) + 0.5*dot(queue_key_latched, 1)  -->  state=1.5*F_END_G\n",
        "[F_NEXT_Q] 0.5*dot(state, NEXT_Q) + 0.25*dot(queue_head_latched, 1) + 0.25*dot(queue_key_latched, 1)  -->  state=1.5*F_NEXT_Q\n",
        "[F_IF] 0.5*dot(state, IF) + 0.5*dot(queue_key_latched, 1)  -->  state=1.5*F_IF\n",
        "[IN_Q] dot(state, IN_Q) - (0.5*dot(temp_latched, 1))  -->  temp=graph_next, temp_latch=1, state=IN_Q\n",
        "[IF] dot(state, IF) - (0.5*dot(queue_key_latched, 1))  -->  queue_key=graph_edge, queue_key_latch=1, state=IF\n",
        "[F_NOTIN_Q] 0.5*dot(state, NOTIN_Q) + 0.166666666667*dot(queue_key_latched, 1) + 0.166666666667*dot(queue_value_latched, 1) + 0.166666666667*dot(queue_learning_latched, 1)  -->  state=1.5*F_NOTIN_Q\n",
        "[IF_TO_NOTIN_Q] 0.5*dot(state, F_IF) + 0.5*(1 - dot(queue_has_key, 1) - dot(queue_key, NULL))  -->  state=1.5*NOTIN_Q\n",
        "[INIT_TO_IF] 0.5*dot(state, F_INIT) + 0.5*(1.0)  -->  state=1.5*IF\n",
        "[ADDED_Q] dot(state, ADDED_Q) - (0.166666666667*dot(queue_tail_latched, 1) + 0.166666666667*dot(queue_learning_latched, 1) + 0.166666666667*dot(temp_latched, 1))  -->  queue_tail=graph_edge, queue_learning=-1, temp=graph_next, queue_tail_latch=1, queue_learning_latch=1, temp_latch=1, state=ADDED_Q\n",
        "[F_ADDED_Q] 0.5*dot(state, ADDED_Q) + 0.166666666667*dot(queue_tail_latched, 1) + 0.166666666667*dot(queue_learning_latched, 1) + 0.166666666667*dot(temp_latched, 1)  -->  state=1.5*F_ADDED_Q\n",
        "[IN_Q_TO_LOOK_G] 0.5*dot(state, F_IN_Q) + 0.5*(1.0)  -->  state=1.5*LOOK_G\n",
        "[IF_TO_END_G] 0.5*dot(state, F_IF) + 0.5*(dot(queue_key, NULL))  -->  state=1.5*END_G\n",
        "[LOOK_G] dot(state, LOOK_G) - (0.5*dot(graph_key_latched, 1))  -->  graph_key=temp, graph_key_latch=1, state=LOOK_G\n",
        "[NOTIN_Q_TO_ADDED_Q] 0.5*dot(state, F_NOTIN_Q) + 0.5*(dot(queue_has_key, 1))  -->  state=1.5*ADDED_Q\n",
        "[LOOK_G_TO_IF] 0.5*dot(state, F_LOOK_G) + 0.5*(1.0)  -->  state=1.5*IF\n",
        "[END_G_TO_NEXT_Q] 0.5*dot(state, F_END_G) + 0.5*(1.0)  -->  state=1.5*NEXT_Q\n",
        "[NOTIN_Q_TO_NOTIN_Q] 0.5*dot(state, F_NOTIN_Q) + 0.5*(0.8)  -->  state=1.5*NOTIN_Q\n"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sim = nengo.Simulator(model)\n",
      "sim.run(1.)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def do_plot(data):\n",
      "    for i, y in enumerate(data.T):\n",
      "        plt.plot(sim.trange(), y, marker=['o', 's', 'v'][i%3])\n",
      "\n",
      "'''\n",
      "INIT = bfs.get_module_output('state')[1].parse('INIT').v\n",
      "        \n",
      "plt.figure(figsize=(10, 10))\n",
      "plt.title(\"Ideal Utility\")\n",
      "plt.plot(sim.trange(), 0.5*np.dot(sim.data[module_probes['state']], INIT) + \n",
      "         0.125*np.dot(sim.data[module_probes['graph_key_latched']], 0.5) + \n",
      "         0.125*np.dot(sim.data[module_probes['queue_head_latched']], 0.5) + \n",
      "         0.125*np.dot(sim.data[module_probes['queue_tail_latched']], 0.5) + \n",
      "         0.125*np.dot(sim.data[module_probes['queue_learning_latched']], 0.5))\n",
      "'''\n",
      "  \n",
      "plt.figure(figsize=(10, 10))\n",
      "plt.title(\"Utilities\")\n",
      "do_plot(sim.data[utilities_probe])\n",
      "plt.legend([action.name for action in bfs.bg.actions.actions])\n",
      "\n",
      "plt.figure(figsize=(10, 10))\n",
      "plt.title(\"BG Output\")\n",
      "do_plot(sim.data[bg_output_probe])\n",
      "plt.legend([action.name for action in bfs.bg.actions.actions])\n",
      "\n",
      "plt.figure(figsize=(10, 10))\n",
      "plt.title(\"Rules\")\n",
      "do_plot(sim.data[actions_probe])\n",
      "plt.legend([action.name for action in bfs.bg.actions.actions])\n",
      "\n",
      "for module, probe in module_probes.items():\n",
      "    plt.figure(figsize=(10, 10))\n",
      "    plt.title(module)\n",
      "    if sim.data[probe].shape[1] == 1:\n",
      "        plt.plot(sim.trange(), sim.data[probe])\n",
      "    else:\n",
      "        do_plot(np.dot(sim.data[probe], bfs.get_module_output(module)[1].vectors.T))\n",
      "        plt.legend(bfs.get_module_output(module)[1].keys, fontsize='small')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    }
   ],
   "metadata": {}
  }
 ]
}