{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "do_save = True\n",
      "do_load = True\n",
      "do_graph = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import nengo\n",
      "import nengo.spa as spa\n",
      "from nengo.utils.compat import OrderedDict\n",
      "from nengo.utils.distributions import Uniform, UniformHypersphere\n",
      "from nengo.networks.associative import AutoAssociative, HeteroAssociative"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "\n",
      "states = {\n",
      "    'INIT': 'graph_key=v_0, queue_head=v_0, queue_tail=v_0, queue_learning=-1',\n",
      "    'IF': 'queue_key=graph_edge',\n",
      "    'IN_Q': 'temp=graph_next',\n",
      "    'LOOK_G': 'graph_key=temp',\n",
      "    'NOTIN_Q': 'queue_key=queue_tail, queue_value=graph_edge, queue_learning=1',\n",
      "    'ADDED_Q': 'queue_tail=graph_edge, queue_learning=-1, temp=graph_next',\n",
      "    'END_G': 'queue_key=queue_head',\n",
      "    'NEXT_Q': 'queue_head=queue_output, queue_key=queue_output',\n",
      "}\n",
      "\n",
      "transitions = {\n",
      "    ('INIT', 'IF') : None,\n",
      "    ('IF', 'END_G') : 'dot(queue_key, NULL)',\n",
      "    ('IF', 'IN_Q') : 'dot(queue_has_key, 1)',\n",
      "    ('IF', 'NOTIN_Q') : '1 - dot(queue_has_key, 1) - dot(queue_key, NULL)',\n",
      "    ('IN_Q', 'LOOK_G') : None,\n",
      "    ('NOTIN_Q', 'NOTIN_Q') : '0.8',\n",
      "    ('NOTIN_Q', 'ADDED_Q') : 'dot(queue_has_key, 1)',\n",
      "    ('ADDED_Q', 'LOOK_G') : None,\n",
      "    ('LOOK_G', 'IF') : None,\n",
      "    ('END_G', 'NEXT_Q') : None,\n",
      "    ('END_G', 'IF') : None,\n",
      "}\n",
      "\n",
      "def dfa_to_actions(states, transitions, state='state', max_state=2.5, gain=4.0, offset=-0.2):\n",
      "    action_matches = {}\n",
      "    action_effects = {}\n",
      "    \n",
      "    weight = 0.5/max_state\n",
      "    r_weight = 0.5\n",
      "        \n",
      "    for (pre, post), utility in transitions.iteritems():\n",
      "        if utility is None:\n",
      "            utility = '1.0'\n",
      "        transition_name = '%s_TO_%s' % (pre, post)\n",
      "        action_matches[transition_name] = '%s*dot(%s, F_%s) + %s*(%s) + %s' % (\n",
      "            weight, state, pre, r_weight, utility, offset)\n",
      "        action_effects[transition_name] = '%s=%s*%s' % (state, gain, post)\n",
      "    \n",
      "    for post, effect in states.iteritems():\n",
      "        \n",
      "        latch_matches = []\n",
      "        latch_effects = []\n",
      "        all_effects = effect.split(',')\n",
      "        for subeffect in all_effects:\n",
      "            lvalue, rvalue = subeffect.split('=', 1)\n",
      "            latch = lvalue.strip()\n",
      "            latch_matches.append('%s*dot(%s_latched, 1)' % (r_weight / len(all_effects), latch))\n",
      "            latch_effects.append('%s_latch=1' % latch)\n",
      "            \n",
      "        action_matches[post] = '%s*dot(%s, %s) - (%s) + %s' % (weight, state, post, ' + '.join(latch_matches), r_weight + offset)\n",
      "        action_effects[post] = '%s, %s, %s=%s' % (effect, ', '.join(latch_effects), state, post)\n",
      "        \n",
      "        action_matches['F_%s' % post] = '%s*dot(%s, %s) + %s + %s' % (\n",
      "            weight, state, post, ' + '.join(latch_matches), offset)\n",
      "        action_effects['F_%s' % post] = '%s=%s*F_%s' % (state, gain, post)\n",
      "\n",
      "    actions = {}\n",
      "    for name in action_matches:\n",
      "        actions[name] = '%s  -->  %s' % (action_matches[name], action_effects[name])\n",
      "    \n",
      "    return actions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class BFS(spa.SPA):\n",
      "\n",
      "    def __init__(self, graph, dimensions, neurons_per_item=500, dimensions_state=64):\n",
      "        super(BFS, self).__init__()\n",
      "        \n",
      "        num_vertices = len(graph)\n",
      "        \n",
      "        # Put the graph into a static Dict\n",
      "        initial_keys = []\n",
      "        initial_values = []\n",
      "        graph_vocab = self.get_default_vocab(dimensions)\n",
      "        for i, adj_list in enumerate(graph):\n",
      "            for num, j in enumerate(adj_list):\n",
      "                if not (0 <= j < num_vertices):\n",
      "                    raise ValueError(\"Edge %d->%d out of range\" % (i, j))\n",
      "                key = 'V_%d' % i if num == 0 else 'P_%d_%d' % (i, num)\n",
      "                next_key = 'P_%d_%d' % (i, num + 1) if num != len(adj_list) - 1 else 'NULL' \n",
      "                initial_keys.append(graph_vocab.parse(key).v)\n",
      "                initial_values.append(graph_vocab.parse('EDGE*V_%d+NEXT*%s' % (j, next_key)).v)\n",
      "            #if not len(adj_list):\n",
      "            #    initial_keys.append(graph_vocab.parse('V_%d' % i).v)\n",
      "            #    initial_values.append('NULL')\n",
      "        \n",
      "        self.graph = AutoAssociative(\n",
      "            nengo.LIF(neurons_per_item*len(initial_keys)), len(initial_keys),\n",
      "            initial_keys=initial_keys, initial_values=initial_values)\n",
      "        \n",
      "        # Interface with the graph using SPA blocks\n",
      "        self.graph_key = spa.DoubleLatch(dimensions=dimensions)\n",
      "        self.graph_output = spa.Buffer(dimensions=dimensions)\n",
      "        nengo.Connection(self.graph_key.state.output, self.graph.key)\n",
      "        nengo.Connection(self.graph.output, self.graph_output.state.input, filter=None)\n",
      "        self.graph_edge = spa.Cleanup(graph_vocab)  # spa.Buffer(dimensions=dimensions)\n",
      "        self.graph_next = spa.Cleanup(graph_vocab)  # spa.Buffer(dimensions=dimensions)\n",
      "\n",
      "        # Create a queue using a Dict and interface with SPA blocks\n",
      "        self.queue = AutoAssociative(\n",
      "            nengo.LIF(neurons_per_item*num_vertices), num_vertices, dimensions, dimensions,\n",
      "            initial_keys=[graph_vocab.parse('V_0').v], initial_values=[graph_vocab.parse('V_0').v])\n",
      "        self.queue_key = spa.DoubleLatch(dimensions=dimensions)\n",
      "        self.queue_value = spa.DoubleLatch(dimensions=dimensions)\n",
      "        self.queue_learning = spa.DoubleLatch(dimensions=1, subdimensions=1)\n",
      "        self.queue_output = spa.Buffer(dimensions=dimensions)\n",
      "        self.queue_has_key = spa.Buffer(dimensions=1, subdimensions=1)\n",
      "        nengo.Connection(self.queue_key.state.output, self.queue.key)\n",
      "        nengo.Connection(self.queue_value.state.output, self.queue.value)\n",
      "        nengo.Connection(self.queue_learning.state.output, self.queue.learning)\n",
      "        nengo.Connection(self.queue.output, self.queue_output.state.input, filter=None)\n",
      "        nengo.Connection(self.queue.has_key, self.queue_has_key.state.input, filter=None)\n",
      "\n",
      "        # Variables\n",
      "        self.state = spa.Memory(dimensions=dimensions_state)\n",
      "        self.temp = spa.DoubleLatch(dimensions=dimensions)\n",
      "        self.queue_head = spa.DoubleLatch(dimensions=dimensions)\n",
      "        self.queue_tail = spa.DoubleLatch(dimensions=dimensions)\n",
      "        \n",
      "        # Input\n",
      "        self.v_0 = spa.Buffer(dimensions=dimensions)\n",
      "        \n",
      "        # Control flow\n",
      "        actions = dfa_to_actions(states, transitions)\n",
      "        for name, action in actions.items():\n",
      "            print \"[%s] %s\" % (name, action)\n",
      "        actions = spa.Actions(**actions)\n",
      "        cortical_actions = spa.Actions('graph_edge=graph_output*~EDGE',\n",
      "                                       'graph_next=graph_output*~NEXT')\n",
      "        self.bg = spa.BasalGanglia(actions=actions, radius=3, n_neurons_per_ensemble=200)\n",
      "        self.thal = spa.Thalamus(self.bg)\n",
      "        self.cortical = spa.Cortical(cortical_actions)\n",
      "        \n",
      "        # Initialize starting vertex and state\n",
      "        self.input_vertex = spa.Input(v_0=lambda t: 'V_0')\n",
      "        self.input_state = spa.Input(state=lambda t: '4*INIT' if t < 0.02 else '0')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graph = [[1, 2],\n",
      "         [0, 3],\n",
      "         [0],\n",
      "         [0, 1, 2]]\n",
      "\n",
      "d = 128\n",
      "\n",
      "model = nengo.Network()\n",
      "with model:\n",
      "    bfs = BFS(graph, d)\n",
      "\n",
      "    modules = ('v_0', 'state', 'graph_key', 'graph_key_latched', \n",
      "               'graph_edge', 'graph_next',\n",
      "               'queue_head', 'queue_head_latched', 'queue_tail', 'queue_tail_latched', \n",
      "               'queue_key', 'queue_key_latched', 'queue_value', 'queue_value_latched', \n",
      "               'queue_learning', 'queue_learning_latched',\n",
      "               'queue_output', 'queue_has_key', \n",
      "               'temp', 'temp_latched')\n",
      "    module_probes = OrderedDict([\n",
      "        (module, nengo.Probe(bfs.get_module_output(module)[0], filter=0.01))\n",
      "        for module in modules])\n",
      "    actions_probe = nengo.Probe(bfs.thal.actions.output, filter=0.03)\n",
      "    utilities_probe = nengo.Probe(bfs.bg.input, filter=0.03)\n",
      "    bg_output_probe = nengo.Probe(bfs.bg.output, filter=0.03)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[NEXT_Q] 0.2*dot(state, NEXT_Q) - (0.25*dot(queue_head_latched, 1) + 0.25*dot(queue_key_latched, 1)) + 0.3  -->  queue_head=queue_output, queue_key=queue_output, queue_head_latch=1, queue_key_latch=1, state=NEXT_Q\n",
        "[ADDED_Q_TO_LOOK_G] 0.2*dot(state, F_ADDED_Q) + 0.5*(1.0) + -0.2  -->  state=4.0*LOOK_G\n",
        "[NOTIN_Q] 0.2*dot(state, NOTIN_Q) - (0.166666666667*dot(queue_key_latched, 1) + 0.166666666667*dot(queue_value_latched, 1) + 0.166666666667*dot(queue_learning_latched, 1)) + 0.3  -->  queue_key=queue_tail, queue_value=graph_edge, queue_learning=1, queue_key_latch=1, queue_value_latch=1, queue_learning_latch=1, state=NOTIN_Q\n",
        "[F_LOOK_G] 0.2*dot(state, LOOK_G) + 0.5*dot(graph_key_latched, 1) + -0.2  -->  state=4.0*F_LOOK_G\n",
        "[END_G] 0.2*dot(state, END_G) - (0.5*dot(queue_key_latched, 1)) + 0.3  -->  queue_key=queue_head, queue_key_latch=1, state=END_G\n",
        "[F_INIT] 0.2*dot(state, INIT) + 0.125*dot(graph_key_latched, 1) + 0.125*dot(queue_head_latched, 1) + 0.125*dot(queue_tail_latched, 1) + 0.125*dot(queue_learning_latched, 1) + -0.2  -->  state=4.0*F_INIT\n",
        "[F_IN_Q] 0.2*dot(state, IN_Q) + 0.5*dot(temp_latched, 1) + -0.2  -->  state=4.0*F_IN_Q\n",
        "[INIT] 0.2*dot(state, INIT) - (0.125*dot(graph_key_latched, 1) + 0.125*dot(queue_head_latched, 1) + 0.125*dot(queue_tail_latched, 1) + 0.125*dot(queue_learning_latched, 1)) + 0.3  -->  graph_key=v_0, queue_head=v_0, queue_tail=v_0, queue_learning=-1, graph_key_latch=1, queue_head_latch=1, queue_tail_latch=1, queue_learning_latch=1, state=INIT\n",
        "[END_G_TO_IF] 0.2*dot(state, F_END_G) + 0.5*(1.0) + -0.2  -->  state=4.0*IF\n",
        "[IF_TO_IN_Q] 0.2*dot(state, F_IF) + 0.5*(dot(queue_has_key, 1)) + -0.2  -->  state=4.0*IN_Q\n",
        "[F_END_G] 0.2*dot(state, END_G) + 0.5*dot(queue_key_latched, 1) + -0.2  -->  state=4.0*F_END_G\n",
        "[F_NEXT_Q] 0.2*dot(state, NEXT_Q) + 0.25*dot(queue_head_latched, 1) + 0.25*dot(queue_key_latched, 1) + -0.2  -->  state=4.0*F_NEXT_Q\n",
        "[F_IF] 0.2*dot(state, IF) + 0.5*dot(queue_key_latched, 1) + -0.2  -->  state=4.0*F_IF\n",
        "[IN_Q] 0.2*dot(state, IN_Q) - (0.5*dot(temp_latched, 1)) + 0.3  -->  temp=graph_next, temp_latch=1, state=IN_Q\n",
        "[IF] 0.2*dot(state, IF) - (0.5*dot(queue_key_latched, 1)) + 0.3  -->  queue_key=graph_edge, queue_key_latch=1, state=IF\n",
        "[F_NOTIN_Q] 0.2*dot(state, NOTIN_Q) + 0.166666666667*dot(queue_key_latched, 1) + 0.166666666667*dot(queue_value_latched, 1) + 0.166666666667*dot(queue_learning_latched, 1) + -0.2  -->  state=4.0*F_NOTIN_Q\n",
        "[IF_TO_NOTIN_Q] 0.2*dot(state, F_IF) + 0.5*(1 - dot(queue_has_key, 1) - dot(queue_key, NULL)) + -0.2  -->  state=4.0*NOTIN_Q\n",
        "[INIT_TO_IF] 0.2*dot(state, F_INIT) + 0.5*(1.0) + -0.2  -->  state=4.0*IF\n",
        "[ADDED_Q] 0.2*dot(state, ADDED_Q) - (0.166666666667*dot(queue_tail_latched, 1) + 0.166666666667*dot(queue_learning_latched, 1) + 0.166666666667*dot(temp_latched, 1)) + 0.3  -->  queue_tail=graph_edge, queue_learning=-1, temp=graph_next, queue_tail_latch=1, queue_learning_latch=1, temp_latch=1, state=ADDED_Q\n",
        "[F_ADDED_Q] 0.2*dot(state, ADDED_Q) + 0.166666666667*dot(queue_tail_latched, 1) + 0.166666666667*dot(queue_learning_latched, 1) + 0.166666666667*dot(temp_latched, 1) + -0.2  -->  state=4.0*F_ADDED_Q\n",
        "[IN_Q_TO_LOOK_G] 0.2*dot(state, F_IN_Q) + 0.5*(1.0) + -0.2  -->  state=4.0*LOOK_G\n",
        "[IF_TO_END_G] 0.2*dot(state, F_IF) + 0.5*(dot(queue_key, NULL)) + -0.2  -->  state=4.0*END_G\n",
        "[LOOK_G] 0.2*dot(state, LOOK_G) - (0.5*dot(graph_key_latched, 1)) + 0.3  -->  graph_key=temp, graph_key_latch=1, state=LOOK_G\n",
        "[NOTIN_Q_TO_ADDED_Q] 0.2*dot(state, F_NOTIN_Q) + 0.5*(dot(queue_has_key, 1)) + -0.2  -->  state=4.0*ADDED_Q\n",
        "[LOOK_G_TO_IF] 0.2*dot(state, F_LOOK_G) + 0.5*(1.0) + -0.2  -->  state=4.0*IF\n",
        "[END_G_TO_NEXT_Q] 0.2*dot(state, F_END_G) + 0.5*(1.0) + -0.2  -->  state=4.0*NEXT_Q\n",
        "[NOTIN_Q_TO_NOTIN_Q] 0.2*dot(state, F_NOTIN_Q) + 0.5*(0.8) + -0.2  -->  state=4.0*NOTIN_Q\n",
        "Warning: Could not create a semantic pointer with max_similarity=0.10 (D=64, M=15)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sim = nengo.Simulator(model)\n",
      "sim.run(0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if do_save:\n",
      "    all_probes = module_probes.items() + [('actions_probe', actions_probe), ('utilities_probe', utilities_probe), ('bg_output_probe', bg_output_probe)]\n",
      "    all_data = dict((name, sim.data[probe]) for name, probe in all_probes) \n",
      "    np.savez('bfs', **all_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if do_load:\n",
      "    module_data = np.load('bfs.npz')\n",
      "    actions_data = all_probes.pop('actions_probe')\n",
      "    utilities_data = all_probes.pop('utilities_probe')\n",
      "    bg_output_data = all_probes.pop('bg_output_probe')\n",
      "else:\n",
      "    module_data = dict((name, sim.data[probe]) for name, probe in module_probes.items())\n",
      "    actions_data = sim.data[actions_probe]\n",
      "    utilities_data = sim.data[utilities_probe]\n",
      "    bg_output_data = sim.data[bg_output_probe]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def do_plot(data):\n",
      "    for i, y in enumerate(data.T):\n",
      "        plt.plot(sim.trange(), y, marker=['o', 's', 'v'][i%3])\n",
      "\n",
      "if do_graph:  \n",
      "    plt.figure(figsize=(10, 10))\n",
      "    plt.title(\"Utilities\")\n",
      "    do_plot(utilities_data)\n",
      "    plt.legend([action.name for action in bfs.bg.actions.actions])\n",
      "    \n",
      "    plt.figure(figsize=(10, 10))\n",
      "    plt.title(\"BG Output\")\n",
      "    do_plot(bg_output_data)\n",
      "    plt.legend([action.name for action in bfs.bg.actions.actions])\n",
      "    \n",
      "    plt.figure(figsize=(10, 10))\n",
      "    plt.title(\"Rules\")\n",
      "    do_plot(actions_data)\n",
      "    plt.legend([action.name for action in bfs.bg.actions.actions])\n",
      "    \n",
      "    for module, data in module_data.items():\n",
      "        plt.figure(figsize=(10, 10))\n",
      "        plt.title(module)\n",
      "        if data.shape[1] == 1:\n",
      "            plt.plot(sim.trange(), data)\n",
      "        else:\n",
      "            do_plot(np.dot(data, bfs.get_module_output(module)[1].vectors.T))\n",
      "            plt.legend(bfs.get_module_output(module)[1].keys, fontsize='small')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    }
   ],
   "metadata": {}
  }
 ]
}